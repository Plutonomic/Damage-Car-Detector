# ğŸš— Damaged Car Image Detection and Preprocessing Pipeline

This project is an end-to-end pipeline that automates preprocessing of car images for **damage detection** using **OpenCV** and a custom **Convolutional Neural Network (CNN)**. The system helps streamline insurance claim processes, repair estimates, and AI-powered visual assessments.

## ğŸ”§ Features

- ğŸ“¸ Upload raw car images
- ğŸ§¼ Image preprocessing pipeline using OpenCV
- ğŸ§  Custom CNN model for damage classification
- ğŸ“Š Exploratory Data Analysis (EDA)
- ğŸŒ Streamlit Web App Interface

---

## ğŸ—‚ Project Structure

```

Damage_Car_Detector/
â”œâ”€â”€ app.py                  # Streamlit app interface
â”œâ”€â”€ cnn.py                  # CNN model definition, training, prediction
â”œâ”€â”€ preprocessing.py        # Image preprocessing utilities using OpenCV
â”œâ”€â”€ eda.py                  # Functions for image EDA
â”œâ”€â”€ car\_damage\_model.h5     # Pre-trained CNN model (optional)
â”œâ”€â”€ damaged_car_images/, not_damaged_car_images          # Folder with test car images
â””â”€â”€ README.md

````

---

## ğŸ–¼ Sample Use Case

Upload a car image via the app. It goes through preprocessing and is then classified as:

- âœ… **Not Damaged**
- âŒ **Damaged**

This can be used in:

- ğŸ¦ Insurance claim automation  
- ğŸ”§ Car repair estimate apps  
- ğŸ“² Smart garage systems

---

## ğŸš€ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/your-username/Damage_car.git
cd Damage_car
````

### 2. Install dependencies

```bash
pip install -r requirements.txt
```

Or manually:

```bash
pip install streamlit tensorflow opencv-python numpy matplotlib seaborn
```

### 3. Run the app

```bash
streamlit run app.py
```

---

## ğŸ“ Dataset

You can train the CNN using a binary-labeled dataset with folders like:

```
dataset/
â”œâ”€â”€ Damaged/
â”‚   â”œâ”€â”€ img1.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ Not_Damaged/
    â”œâ”€â”€ img2.jpg
    â””â”€â”€ ...
```

> âœ… You can download such datasets from [Kaggle](https://www.kaggle.com/datasets) or annotate your own.

---

## ğŸ“Š Model Summary

* Input shape: `(256, 256, 3)`
* Layers:

  * 3 Convolution + MaxPooling
  * Flatten â†’ Dense (128) â†’ Dropout â†’ Dense (1, Sigmoid)
* Loss: `binary_crossentropy`
* Optimizer: `Adam`

---

## ğŸ’¡ Future Improvements

* ğŸ“ˆ Train on larger datasets
* ğŸ· Use multi-class classification (minor, major, total loss)
* â˜ï¸ Deploy via cloud (e.g., Streamlit Cloud, Heroku)
* ğŸ”„ Integrate real-time mobile capture

---

## ğŸ§‘â€ğŸ’» Author

* Dann Berlin â€“ [@Plutonomic](https://github.com/Plutonomic)

---

## ğŸ“„ License

This project is licensed under the MIT License.
#See the [LICENSE](LICENSE) file for details.
